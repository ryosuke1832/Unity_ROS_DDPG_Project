#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æŠŠæŒåŠ›åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ 

f_grip_force_classifier_improved.py ã§å­¦ç¿’ã—ãŸåˆ†é¡æ©Ÿã‚’ä½¿ç”¨ã—ã¦ã€
e_tcp_lsl_sync_system.py ã§å–å¾—ã—ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†é¡

æ©Ÿèƒ½:
1. æ”¹å–„ç‰ˆåˆ†é¡æ©Ÿãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
2. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ LSL/TCPãƒ‡ãƒ¼ã‚¿ã®å–å¾—
3. ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã”ã¨ã®æŠŠæŒåŠ›åˆ†é¡ï¼ˆUnderGrip/Success/OverGripï¼‰
4. åˆ†é¡çµæœã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºãƒ»ä¿å­˜
5. çµ±è¨ˆæƒ…å ±ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from sklearn.preprocessing import StandardScaler, LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
import os
import glob
import json
import time
import threading
import queue
from datetime import datetime
from collections import deque, Counter
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

# æ—¢å­˜ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from e_tcp_lsl_sync_system import LSLTCPEpisodeCollector, Episode
from f_grip_force_classifier_improved import ImprovedGripForceClassifier

# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ğŸ¯ ãƒ‡ãƒã‚¤ã‚¹: {device}")

class RealtimeGripForceClassifier:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æŠŠæŒåŠ›åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, model_path=None, lsl_stream_name='MockEEG', tcp_host='127.0.0.1', tcp_port=12345):
        """
        åˆæœŸåŒ–
        
        Args:
            model_path: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
            lsl_stream_name: LSLã‚¹ãƒˆãƒªãƒ¼ãƒ å
            tcp_host: TCPãƒ›ã‚¹ãƒˆ
            tcp_port: TCPãƒãƒ¼ãƒˆ
        """
        self.model_path = model_path
        self.lsl_stream_name = lsl_stream_name
        self.tcp_host = tcp_host
        self.tcp_port = tcp_port
        
        # ãƒ¢ãƒ‡ãƒ«é–¢é€£
        self.model = None
        self.scaler = None
        self.label_encoder = None
        self.class_names = None
        self.input_size = None
        
        # ãƒ‡ãƒ¼ã‚¿åé›†ã‚·ã‚¹ãƒ†ãƒ 
        self.episode_collector = None
        
        # åˆ†é¡çµæœä¿å­˜
        self.classification_results = []
        self.classification_queue = queue.Queue()
        
        # å®Ÿè¡Œåˆ¶å¾¡
        self.is_running = False
        self.classification_thread = None
        
        # çµ±è¨ˆæƒ…å ±
        self.stats = {
            'total_episodes': 0,
            'total_classifications': 0,
            'class_counts': {'UnderGrip': 0, 'Success': 0, 'OverGrip': 0},
            'avg_confidence': 0.0,
            'avg_processing_time_ms': 0.0,
            'start_time': None
        }
        
        # çµæœä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.session_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.output_dir = f"DDPG_Python/logs/realtime_classification_{self.session_id}"
        os.makedirs(self.output_dir, exist_ok=True)
        
        print(f"ğŸ§  ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æŠŠæŒåŠ›åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–")
        print(f"   ã‚»ãƒƒã‚·ãƒ§ãƒ³ID: {self.session_id}")
        print(f"   å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")

    def classify_features(self, features: np.ndarray):
        """
        ç‰¹å¾´é‡ã‹ã‚‰åˆ†é¡ç¢ºç‡ã‚’å–å¾—ï¼ˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ5ã§è¦æ±‚ã•ã‚ŒãŸãƒ¡ã‚½ãƒƒãƒ‰ï¼‰
        
        Args:
            features: æŠ½å‡ºã•ã‚ŒãŸç‰¹å¾´é‡
            
        Returns:
            dict: åˆ†é¡çµæœï¼ˆprobabilitieså«ã‚€ï¼‰
        """
        if self.model is None or self.scaler is None or self.class_names is None:
            print("âš ï¸ åˆ†é¡å™¨ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ - ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç¢ºç‡ã‚’è¿”ã—ã¾ã™")
            return {
                'probabilities': {
                    'UnderGrip': 1/3, 
                    'Success': 1/3, 
                    'OverGrip': 1/3
                }
            }
        
        try:
            # å…¥åŠ›æ¬¡å…ƒåˆã‚ã›
            if features.shape[0] != self.input_size:
                if features.shape[0] < self.input_size:
                    features = np.pad(features, (0, self.input_size - features.shape[0]), 'constant')
                else:
                    features = features[:self.input_size]
            
            # æ­£è¦åŒ–
            X = self.scaler.transform(features.reshape(1, -1))
            
            # æ¨è«–å®Ÿè¡Œ
            with torch.no_grad():
                logits = self.model(torch.FloatTensor(X).to(device))
                probs = torch.softmax(logits, dim=1)[0].cpu().numpy()
            
            # çµæœæ•´å½¢
            probabilities = dict(zip(self.class_names, probs))
            
            return {
                'probabilities': probabilities
            }
            
        except Exception as e:
            print(f"âš ï¸ åˆ†é¡å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'probabilities': {
                    'UnderGrip': 1/3, 
                    'Success': 1/3, 
                    'OverGrip': 1/3
                }
            }
    
    def load_model(self, model_path=None):
        """å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        if model_path is None:
            # æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•æ¤œç´¢
            model_files = glob.glob("DDPG_Python/models/improved_grip_force_classifier_*.pth")
            if not model_files:
                model_files = glob.glob("models/improved_grip_force_classifier_*.pth")
            
            if not model_files:
                print("âŒ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                print("   f_grip_force_classifier_improved.py ã§åˆ†é¡æ©Ÿã‚’å­¦ç¿’ã—ã¦ãã ã•ã„")
                return False
            
            model_path = max(model_files)  # æœ€æ–°ã®ãƒ¢ãƒ‡ãƒ«
            print(f"ğŸ” æœ€æ–°ãƒ¢ãƒ‡ãƒ«è‡ªå‹•é¸æŠ: {model_path}")
        
        try:
            print(f"ğŸ“‚ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ä¸­: {model_path}")
            
            # ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼ˆPyTorch 2.6å¯¾å¿œï¼‰
            try:
                # æ–¹æ³•1: å®‰å…¨ãªã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚’æŒ‡å®šã—ã¦èª­ã¿è¾¼ã¿
                with torch.serialization.safe_globals([
                    StandardScaler, 
                    LabelEncoder,
                    np.ndarray,
                    np.float64,
                    np.int64
                ]):
                    checkpoint = torch.load(model_path, map_location=device, weights_only=True)
                print(f"âœ… å®‰å…¨ãƒ¢ãƒ¼ãƒ‰ã§èª­ã¿è¾¼ã¿æˆåŠŸ")
            except Exception as e1:
                print(f"âš ï¸ å®‰å…¨ãƒ¢ãƒ¼ãƒ‰èª­ã¿è¾¼ã¿å¤±æ•—: {e1}")
                try:
                    # æ–¹æ³•2: weights_only=Falseã§èª­ã¿è¾¼ã¿ï¼ˆä¿¡é ¼ã§ãã‚‹ã‚½ãƒ¼ã‚¹ï¼‰
                    checkpoint = torch.load(model_path, map_location=device, weights_only=False)
                    print(f"âœ… äº’æ›ãƒ¢ãƒ¼ãƒ‰ã§èª­ã¿è¾¼ã¿æˆåŠŸ")
                except Exception as e2:
                    print(f"âŒ äº’æ›ãƒ¢ãƒ¼ãƒ‰èª­ã¿è¾¼ã¿å¤±æ•—: {e2}")
                    raise e2
            
            # ãƒ¢ãƒ‡ãƒ«æƒ…å ±å–å¾—
            self.input_size = checkpoint['input_size']
            self.class_names = checkpoint['class_names']
            self.scaler = checkpoint['scaler']
            self.label_encoder = checkpoint['label_encoder']
            
            # ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
            self.model = ImprovedGripForceClassifier(
                input_size=self.input_size,
                num_classes=len(self.class_names)
            ).to(device)
            
            # å­¦ç¿’æ¸ˆã¿é‡ã¿èª­ã¿è¾¼ã¿
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.model.eval()
            
            # ãƒ†ã‚¹ãƒˆçµæœå–å¾—ï¼ˆå‚è€ƒç”¨ï¼‰
            test_results = checkpoint.get('test_results', {})
            test_accuracy = test_results.get('accuracy', 'unknown')
            test_f1 = test_results.get('f1_score', 'unknown')
            
            print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†:")
            print(f"   å…¥åŠ›ã‚µã‚¤ã‚º: {self.input_size}æ¬¡å…ƒ")
            print(f"   ã‚¯ãƒ©ã‚¹æ•°: {len(self.class_names)}ã‚¯ãƒ©ã‚¹")
            print(f"   ã‚¯ãƒ©ã‚¹å: {list(self.class_names)}")
            print(f"   å­¦ç¿’æ™‚ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_accuracy}")
            print(f"   å­¦ç¿’æ™‚F1ã‚¹ã‚³ã‚¢: {test_f1}")
            
            self.model_path = model_path
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def extract_eeg_features(self, eeg_data):
        """
        EEGãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡ºï¼ˆæ”¹å–„ç‰ˆåˆ†é¡æ©Ÿã¨åŒã˜å‡¦ç†ï¼‰
        
        Args:
            eeg_data: EEGãƒ‡ãƒ¼ã‚¿ (samples, channels)
            
        Returns:
            features: ç‰¹å¾´é‡é…åˆ— (n_features,)
        """
        features = []
        
        # å„ãƒãƒ£ãƒ³ãƒãƒ«ã‹ã‚‰ç‰¹å¾´é‡ã‚’æŠ½å‡º
        for ch in range(eeg_data.shape[1]):  # 32ãƒãƒ£ãƒ³ãƒãƒ«
            ch_data = eeg_data[:, ch]
            
            # æ™‚é–“ãƒ‰ãƒ¡ã‚¤ãƒ³çµ±è¨ˆçš„ç‰¹å¾´é‡
            features.extend([
                np.mean(ch_data),              # å¹³å‡
                np.std(ch_data),               # æ¨™æº–åå·®
                np.var(ch_data),               # åˆ†æ•£
                np.min(ch_data),               # æœ€å°å€¤
                np.max(ch_data),               # æœ€å¤§å€¤
                np.median(ch_data),            # ä¸­å¤®å€¤
                np.percentile(ch_data, 25),    # ç¬¬1å››åˆ†ä½æ•°
                np.percentile(ch_data, 75),    # ç¬¬3å››åˆ†ä½æ•°
                np.ptp(ch_data),               # ãƒ¬ãƒ³ã‚¸ï¼ˆæœ€å¤§-æœ€å°ï¼‰
                len(ch_data[ch_data > 0]) / len(ch_data)  # æ­£ã®å€¤ã®å‰²åˆ
            ])
            
            # å‘¨æ³¢æ•°ãƒ‰ãƒ¡ã‚¤ãƒ³ç‰¹å¾´é‡
            try:
                fft = np.fft.fft(ch_data)
                freqs = np.fft.fftfreq(len(ch_data), 1/250)  # 250Hz
                power_spectrum = np.abs(fft)**2
                
                # å„å‘¨æ³¢æ•°å¸¯åŸŸã®ãƒ‘ãƒ¯ãƒ¼
                # ãƒ‡ãƒ«ã‚¿æ³¢ (0.5-4Hz)
                delta_mask = (freqs >= 0.5) & (freqs <= 4)
                delta_power = np.mean(power_spectrum[delta_mask]) if np.any(delta_mask) else 0
                
                # ã‚·ãƒ¼ã‚¿æ³¢ (4-8Hz)
                theta_mask = (freqs >= 4) & (freqs <= 8)
                theta_power = np.mean(power_spectrum[theta_mask]) if np.any(theta_mask) else 0
                
                # ã‚¢ãƒ«ãƒ•ã‚¡æ³¢ (8-12Hz)
                alpha_mask = (freqs >= 8) & (freqs <= 12)
                alpha_power = np.mean(power_spectrum[alpha_mask]) if np.any(alpha_mask) else 0
                
                # ãƒ™ãƒ¼ã‚¿æ³¢ (12-30Hz)
                beta_mask = (freqs >= 12) & (freqs <= 30)
                beta_power = np.mean(power_spectrum[beta_mask]) if np.any(beta_mask) else 0
                
                # ã‚¬ãƒ³ãƒæ³¢ (30-100Hz)
                gamma_mask = (freqs >= 30) & (freqs <= 100)
                gamma_power = np.mean(power_spectrum[gamma_mask]) if np.any(gamma_mask) else 0
                
                features.extend([delta_power, theta_power, alpha_power, beta_power, gamma_power])
                
            except:
                # FFTã‚¨ãƒ©ãƒ¼æ™‚ã¯0ã§åŸ‹ã‚ã‚‹
                features.extend([0, 0, 0, 0, 0])
        
        # ãƒãƒ£ãƒ³ãƒãƒ«é–“ã®ç›¸é–¢ç‰¹å¾´é‡ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        try:
            corr_matrix = np.corrcoef(eeg_data.T)
            # ä¸Šä¸‰è§’è¡Œåˆ—ã®è¦ç´ ã‚’ç‰¹å¾´é‡ã¨ã—ã¦ä½¿ç”¨
            upper_tri_indices = np.triu_indices(32, k=1)
            corr_features = corr_matrix[upper_tri_indices]
            
            # ç›¸é–¢ã®çµ±è¨ˆé‡
            features.extend([
                np.mean(corr_features),
                np.std(corr_features),
                np.max(corr_features),
                np.min(corr_features)
            ])
        except:
            features.extend([0, 0, 0, 0])
        
        return np.array(features)
    
    def classify_episode(self, episode):
        """
        ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†é¡
        
        Args:
            episode: Episodeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
            
        Returns:
            classification_result: åˆ†é¡çµæœè¾æ›¸
        """
        start_time = time.time()
        
        try:
            # EEGãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´é‡æŠ½å‡º
            eeg_features = self.extract_eeg_features(episode.lsl_data)
            
            # ç‰¹å¾´é‡æ¬¡å…ƒãƒã‚§ãƒƒã‚¯
            if len(eeg_features) != self.input_size:
                print(f"âš ï¸ ç‰¹å¾´é‡æ¬¡å…ƒä¸ä¸€è‡´: {len(eeg_features)} != {self.input_size}")
                # æ¬¡å…ƒèª¿æ•´
                if len(eeg_features) < self.input_size:
                    eeg_features = np.pad(eeg_features, (0, self.input_size - len(eeg_features)), 'constant')
                else:
                    eeg_features = eeg_features[:self.input_size]
            
            # ç‰¹å¾´é‡æ­£è¦åŒ–
            eeg_features_scaled = self.scaler.transform(eeg_features.reshape(1, -1))
            
            # Pytorchãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
            features_tensor = torch.FloatTensor(eeg_features_scaled).to(device)
            
            # åˆ†é¡å®Ÿè¡Œ
            with torch.no_grad():
                outputs = self.model(features_tensor)
                probabilities = torch.softmax(outputs, dim=1)
                predicted_class_idx = torch.argmax(probabilities, dim=1).item()
                confidence = probabilities[0, predicted_class_idx].item()
            
            predicted_class = self.class_names[predicted_class_idx]
            
            # å‡¦ç†æ™‚é–“è¨ˆç®—
            processing_time_ms = (time.time() - start_time) * 1000
            
            # TCPãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å®Ÿéš›ã®æŠŠæŒåŠ›ã‚’å–å¾—
            actual_grip_force = episode.tcp_data.get('grip_force', 0.0)
            
            # å®Ÿéš›ã®ãƒ©ãƒ™ãƒ«ã‚’è¨ˆç®—ï¼ˆå‚è€ƒç”¨ï¼‰
            if actual_grip_force < 8.0:
                actual_label = "UnderGrip"
            elif actual_grip_force > 15.0:
                actual_label = "OverGrip"
            else:
                actual_label = "Success"
            
            # åˆ†é¡çµæœä½œæˆ
            classification_result = {
                'episode_id': episode.episode_id,
                'timestamp': time.time(),
                'predicted_class': predicted_class,
                'predicted_class_idx': predicted_class_idx,
                'confidence': confidence,
                'probabilities': {
                    class_name: prob.item() 
                    for class_name, prob in zip(self.class_names, probabilities[0])
                },
                'actual_grip_force': actual_grip_force,
                'actual_label': actual_label,
                'correct_prediction': predicted_class == actual_label,
                'processing_time_ms': processing_time_ms,
                'eeg_data_shape': episode.lsl_data.shape,
                'tcp_data': episode.tcp_data,
                'sync_latency_ms': episode.sync_latency
            }
            
            return classification_result
            
        except Exception as e:
            print(f"âŒ åˆ†é¡ã‚¨ãƒ©ãƒ¼ (Episode {episode.episode_id}): {e}")
            import traceback
            traceback.print_exc()
            
            return {
                'episode_id': episode.episode_id,
                'timestamp': time.time(),
                'error': str(e),
                'processing_time_ms': (time.time() - start_time) * 1000
            }
    
    def start_classification(self):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†é¡é–‹å§‹"""
        print(f"ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†é¡é–‹å§‹")
        
        if self.model is None:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åé›†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        self.episode_collector = LSLTCPEpisodeCollector(
            lsl_stream_name=self.lsl_stream_name,
            tcp_host=self.tcp_host,
            tcp_port=self.tcp_port,
            save_to_csv=False  # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†é¡ã§ã¯ç„¡åŠ¹
        )
        
        # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åé›†é–‹å§‹
        if not self.episode_collector.start_collection():
            print(f"âŒ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åé›†é–‹å§‹å¤±æ•—")
            return False
        
        # åˆ†é¡ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        self.is_running = True
        self.stats['start_time'] = time.time()
        self.classification_thread = threading.Thread(target=self._classification_loop, daemon=True)
        self.classification_thread.start()
        
        print(f"âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†é¡é–‹å§‹å®Œäº†")
        print(f"ğŸ’¡ Unityå´ã§ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        return True
    
    def _classification_loop(self):
        """åˆ†é¡å‡¦ç†ãƒ«ãƒ¼ãƒ—"""
        print(f"ğŸ”„ åˆ†é¡å‡¦ç†ãƒ«ãƒ¼ãƒ—é–‹å§‹")
        
        last_episode_count = 0
        
        while self.is_running:
            try:
                # æ–°ã—ã„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
                current_episode_count = len(self.episode_collector.episodes)
                
                if current_episode_count > last_episode_count:
                    # æ–°ã—ã„ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’å‡¦ç†
                    for i in range(last_episode_count, current_episode_count):
                        episode = self.episode_collector.episodes[i]
                        
                        print(f"ğŸ†• æ–°ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ¤œå‡º: Episode {episode.episode_id}")
                        
                        # åˆ†é¡å®Ÿè¡Œ
                        classification_result = self.classify_episode(episode)
                        
                        # çµæœå‡¦ç†
                        self._process_classification_result(classification_result)
                        
                        # çµ±è¨ˆæ›´æ–°
                        self._update_statistics(classification_result)
                    
                    last_episode_count = current_episode_count
                
                time.sleep(0.1)  # 100mså¾…æ©Ÿ
                
            except Exception as e:
                print(f"âŒ åˆ†é¡ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(1.0)
        
        print(f"ğŸ”„ åˆ†é¡å‡¦ç†ãƒ«ãƒ¼ãƒ—çµ‚äº†")
    
    def _process_classification_result(self, result):
        """åˆ†é¡çµæœã®å‡¦ç†"""
        if 'error' in result:
            print(f"âŒ åˆ†é¡å¤±æ•— (Episode {result['episode_id']}): {result['error']}")
            return
        
        # çµæœä¿å­˜
        self.classification_results.append(result)
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤º
        print(f"ğŸ¯ åˆ†é¡çµæœ (Episode {result['episode_id']}):")
        print(f"   äºˆæ¸¬ã‚¯ãƒ©ã‚¹: {result['predicted_class']} (ä¿¡é ¼åº¦: {result['confidence']:.3f})")
        print(f"   å®Ÿéš›ã®æŠŠæŒåŠ›: {result['actual_grip_force']:.2f}N")
        print(f"   å®Ÿéš›ã®ãƒ©ãƒ™ãƒ«: {result['actual_label']}")
        print(f"   æ­£è§£: {'âœ…' if result['correct_prediction'] else 'âŒ'}")
        print(f"   å‡¦ç†æ™‚é–“: {result['processing_time_ms']:.1f}ms")
        
        # è©³ç´°ãªç¢ºç‡è¡¨ç¤º
        print(f"   ã‚¯ãƒ©ã‚¹ç¢ºç‡:")
        for class_name, prob in result['probabilities'].items():
            print(f"     {class_name}: {prob:.3f}")
        
        # CSVä¿å­˜ï¼ˆé€æ¬¡è¿½è¨˜ï¼‰
        self._save_result_to_csv(result)
        
        print()  # ç©ºè¡Œ
    
    def _save_result_to_csv(self, result):
        """åˆ†é¡çµæœã‚’CSVã«ä¿å­˜"""
        try:
            csv_file = os.path.join(self.output_dir, "realtime_classifications.csv")
            
            # CSVãƒ‡ãƒ¼ã‚¿æº–å‚™
            csv_data = {
                'episode_id': result['episode_id'],
                'timestamp': result['timestamp'],
                'predicted_class': result['predicted_class'],
                'predicted_class_idx': result['predicted_class_idx'],
                'confidence': result['confidence'],
                'prob_undergrip': result['probabilities'].get('UnderGrip', 0),
                'prob_success': result['probabilities'].get('Success', 0),
                'prob_overgrip': result['probabilities'].get('OverGrip', 0),
                'actual_grip_force': result['actual_grip_force'],
                'actual_label': result['actual_label'],
                'correct_prediction': result['correct_prediction'],
                'processing_time_ms': result['processing_time_ms'],
                'sync_latency_ms': result['sync_latency_ms']
            }
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ãƒ˜ãƒƒãƒ€ãƒ¼ä»˜ãã§ä½œæˆ
            if not os.path.exists(csv_file):
                pd.DataFrame([csv_data]).to_csv(csv_file, index=False)
            else:
                pd.DataFrame([csv_data]).to_csv(csv_file, mode='a', header=False, index=False)
                
        except Exception as e:
            print(f"âš ï¸ CSVä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def _update_statistics(self, result):
        """çµ±è¨ˆæƒ…å ±ã‚’æ›´æ–°"""
        if 'error' in result:
            return
        
        self.stats['total_episodes'] += 1
        self.stats['total_classifications'] += 1
        
        # ã‚¯ãƒ©ã‚¹åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ
        predicted_class = result['predicted_class']
        if predicted_class in self.stats['class_counts']:
            self.stats['class_counts'][predicted_class] += 1
        
        # å¹³å‡ä¿¡é ¼åº¦
        prev_avg_conf = self.stats['avg_confidence']
        n = self.stats['total_classifications']
        self.stats['avg_confidence'] = (prev_avg_conf * (n-1) + result['confidence']) / n
        
        # å¹³å‡å‡¦ç†æ™‚é–“
        prev_avg_time = self.stats['avg_processing_time_ms']
        self.stats['avg_processing_time_ms'] = (prev_avg_time * (n-1) + result['processing_time_ms']) / n
    
    def stop_classification(self):
        """åˆ†é¡å‡¦ç†åœæ­¢"""
        print(f"ğŸ›‘ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†é¡åœæ­¢ä¸­...")
        
        self.is_running = False
        
        # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åé›†åœæ­¢
        if self.episode_collector:
            self.episode_collector.stop_collection()
        
        # æœ€çµ‚çµ±è¨ˆè¡¨ç¤º
        self._print_final_statistics()
        
        # çµæœåˆ†æ
        if len(self.classification_results) > 0:
            self._analyze_results()
        
        print(f"ğŸ›‘ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†é¡åœæ­¢å®Œäº†")
    
    def _print_final_statistics(self):
        """æœ€çµ‚çµ±è¨ˆæƒ…å ±è¡¨ç¤º"""
        print(f"\nğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†é¡çµ±è¨ˆ:")
        
        if self.stats['start_time']:
            total_time = time.time() - self.stats['start_time']
            print(f"   ç¨¼åƒæ™‚é–“: {total_time:.1f}ç§’")
        
        print(f"   ç·ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æ•°: {self.stats['total_episodes']}")
        print(f"   ç·åˆ†é¡æ•°: {self.stats['total_classifications']}")
        print(f"   å¹³å‡ä¿¡é ¼åº¦: {self.stats['avg_confidence']:.3f}")
        print(f"   å¹³å‡å‡¦ç†æ™‚é–“: {self.stats['avg_processing_time_ms']:.1f}ms")
        
        print(f"   ã‚¯ãƒ©ã‚¹åˆ¥äºˆæ¸¬æ•°:")
        for class_name, count in self.stats['class_counts'].items():
            percentage = count / self.stats['total_classifications'] * 100 if self.stats['total_classifications'] > 0 else 0
            print(f"     {class_name}: {count}ä»¶ ({percentage:.1f}%)")
        
        print(f"   å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.output_dir}")
    
    def _analyze_results(self):
        """åˆ†é¡çµæœã®è©³ç´°åˆ†æ"""
        print(f"\nğŸ“ˆ åˆ†é¡çµæœåˆ†æ:")
        
        # æ­£è§£ç‡è¨ˆç®—
        correct_predictions = [r for r in self.classification_results if r.get('correct_prediction', False)]
        accuracy = len(correct_predictions) / len(self.classification_results) * 100
        print(f"   ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç²¾åº¦: {accuracy:.1f}% ({len(correct_predictions)}/{len(self.classification_results)})")
        
        # ã‚¯ãƒ©ã‚¹åˆ¥æ­£è§£ç‡
        class_accuracies = {}
        for class_name in self.class_names:
            class_results = [r for r in self.classification_results if r.get('actual_label') == class_name]
            if class_results:
                class_correct = [r for r in class_results if r.get('correct_prediction', False)]
                class_acc = len(class_correct) / len(class_results) * 100
                class_accuracies[class_name] = class_acc
                print(f"   {class_name}ç²¾åº¦: {class_acc:.1f}% ({len(class_correct)}/{len(class_results)})")
        
        # ä¿¡é ¼åº¦åˆ†å¸ƒ
        confidences = [r['confidence'] for r in self.classification_results if 'confidence' in r]
        if confidences:
            print(f"   ä¿¡é ¼åº¦åˆ†å¸ƒ:")
            print(f"     æœ€å¤§: {max(confidences):.3f}")
            print(f"     æœ€å°: {min(confidences):.3f}")
            print(f"     å¹³å‡: {np.mean(confidences):.3f}")
            print(f"     æ¨™æº–åå·®: {np.std(confidences):.3f}")
        
        # å‡¦ç†æ™‚é–“çµ±è¨ˆ
        processing_times = [r['processing_time_ms'] for r in self.classification_results if 'processing_time_ms' in r]
        if processing_times:
            print(f"   å‡¦ç†æ™‚é–“çµ±è¨ˆ:")
            print(f"     å¹³å‡: {np.mean(processing_times):.1f}ms")
            print(f"     æœ€å¤§: {max(processing_times):.1f}ms")
            print(f"     æœ€å°: {min(processing_times):.1f}ms")
        
        # æ··åŒè¡Œåˆ—ã®ç°¡æ˜“è¡¨ç¤º
        try:
            from sklearn.metrics import confusion_matrix, classification_report
            
            actual_labels = [r['actual_label'] for r in self.classification_results if 'actual_label' in r]
            predicted_labels = [r['predicted_class'] for r in self.classification_results if 'predicted_class' in r]
            
            if len(actual_labels) == len(predicted_labels) and len(set(actual_labels)) > 1:
                print(f"\nğŸ¯ æ··åŒè¡Œåˆ—:")
                cm = confusion_matrix(actual_labels, predicted_labels, labels=list(self.class_names))
                
                for i, true_class in enumerate(self.class_names):
                    row_str = f"   {true_class:10}: "
                    for j, pred_class in enumerate(self.class_names):
                        row_str += f"{cm[i,j]:3d} "
                    print(row_str)
                
                print(f"   äºˆæ¸¬â†’        " + "".join([f"{cls[:3]:>4}" for cls in self.class_names]))
        except ImportError:
            print(f"   æ··åŒè¡Œåˆ—è¡¨ç¤ºã«ã¯scikit-learnãŒå¿…è¦ã§ã™")
        except Exception as e:
            print(f"   æ··åŒè¡Œåˆ—è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
    
    def run_demo(self):
        """ãƒ‡ãƒ¢å®Ÿè¡Œ"""
        print(f"ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æŠŠæŒåŠ›åˆ†é¡ãƒ‡ãƒ¢é–‹å§‹")
        
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        if not self.load_model():
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å¤±æ•—")
            return
        
        # åˆ†é¡é–‹å§‹
        if not self.start_classification():
            print(f"âŒ åˆ†é¡é–‹å§‹å¤±æ•—")
            return
        
        try:
            print(f"\nğŸ’¡ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†é¡å®Ÿè¡Œä¸­:")
            print(f"   1. LSLãƒ‡ãƒ¼ã‚¿å—ä¿¡ä¸­ ({self.lsl_stream_name})")
            print(f"   2. TCPæ¥ç¶šå¾…æ©Ÿä¸­ ({self.tcp_host}:{self.tcp_port})")
            print(f"   3. ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã”ã¨ã«è‡ªå‹•åˆ†é¡")
            print(f"   4. Ctrl+C ã§çµ‚äº†")
            print(f"\nğŸ® Unityå´ã§ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„:")
            print(f"   1. ãƒ­ãƒœãƒƒãƒˆçŠ¶æ…‹ãƒ‡ãƒ¼ã‚¿é€ä¿¡")
            print(f"   2. 'EPISODE_END' ãƒˆãƒªã‚¬ãƒ¼é€ä¿¡")
            print(f"   â†’ è‡ªå‹•çš„ã«æŠŠæŒåŠ›åˆ†é¡ãŒå®Ÿè¡Œã•ã‚Œã¾ã™")
            
            # ãƒ¡ã‚¤ãƒ³ãƒ«ãƒ¼ãƒ—
            while self.is_running:
                time.sleep(5.0)
                
                # å®šæœŸçš„ãªçµ±è¨ˆè¡¨ç¤º
                if self.stats['total_classifications'] > 0:
                    print(f"ğŸ’» é€²æ—: åˆ†é¡æ¸ˆã¿ {self.stats['total_classifications']}ä»¶, "
                          f"å¹³å‡ä¿¡é ¼åº¦ {self.stats['avg_confidence']:.3f}, "
                          f"å¹³å‡å‡¦ç†æ™‚é–“ {self.stats['avg_processing_time_ms']:.1f}ms")
                else:
                    print(f"â³ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰å¾…æ©Ÿä¸­...")
                
        except KeyboardInterrupt:
            print(f"\nâ¹ï¸ ãƒ‡ãƒ¢åœæ­¢ï¼ˆCtrl+Cï¼‰")
        finally:
            self.stop_classification()


class BatchClassificationTester:
    """ãƒãƒƒãƒåˆ†é¡ãƒ†ã‚¹ã‚¿ãƒ¼ï¼ˆéå»ã®CSVãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆï¼‰"""
    
    def __init__(self, classifier):
        self.classifier = classifier
    
    def test_with_saved_episodes(self, csv_dir):
        """ä¿å­˜ã•ã‚ŒãŸã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰CSVã§ãƒ†ã‚¹ãƒˆ"""
        print(f"ğŸ§ª ä¿å­˜ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã§ãƒãƒƒãƒãƒ†ã‚¹ãƒˆé–‹å§‹: {csv_dir}")
        
        if not os.path.exists(csv_dir):
            print(f"âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_dir}")
            return False
        
        # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰CSVãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢
        info_files = glob.glob(os.path.join(csv_dir, "*_info.csv"))
        eeg_files = glob.glob(os.path.join(csv_dir, "*_eeg.csv"))
        
        print(f"ğŸ“‹ ç™ºè¦‹ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰: {len(info_files)}ä»¶")
        
        if len(info_files) == 0:
            print(f"âŒ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return False
        
        test_results = []
        
        for info_file in sorted(info_files):
            try:
                # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æƒ…å ±èª­ã¿è¾¼ã¿
                info_df = pd.read_csv(info_file)
                episode_id = info_df['episode_id'].iloc[0]
                
                # EEGãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
                eeg_file = info_file.replace('_info.csv', '_eeg.csv')
                if not os.path.exists(eeg_file):
                    print(f"âš ï¸ EEGãƒ•ã‚¡ã‚¤ãƒ«æœªç™ºè¦‹: {eeg_file}")
                    continue
                
                eeg_df = pd.read_csv(eeg_file)
                channel_cols = [col for col in eeg_df.columns if col.startswith('ch_')]
                eeg_data = eeg_df[channel_cols].values[:300, :32]  # 300ã‚µãƒ³ãƒ—ãƒ«ã€32ãƒãƒ£ãƒ³ãƒãƒ«
                
                # ãƒ¢ãƒƒã‚¯ Episodeã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ
                mock_episode = type('Episode', (), {
                    'episode_id': episode_id,
                    'lsl_data': eeg_data,
                    'tcp_data': {
                        'grip_force': info_df['grip_force'].iloc[0],
                        'contact': info_df['contact'].iloc[0],
                        'broken': info_df['broken'].iloc[0]
                    },
                    'sync_latency': info_df.get('sync_latency_ms', [0]).iloc[0]
                })()
                
                # åˆ†é¡å®Ÿè¡Œ
                result = self.classifier.classify_episode(mock_episode)
                test_results.append(result)
                
                # é€²æ—è¡¨ç¤º
                if len(test_results) % 10 == 0:
                    print(f"   ãƒ†ã‚¹ãƒˆé€²æ—: {len(test_results)}/{len(info_files)}")
                
            except Exception as e:
                print(f"âš ï¸ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰{episode_id}ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
                continue
        
        print(f"âœ… ãƒãƒƒãƒãƒ†ã‚¹ãƒˆå®Œäº†: {len(test_results)}ä»¶")
        
        # çµæœåˆ†æ
        self._analyze_batch_results(test_results)
        
        return test_results
    
    def _analyze_batch_results(self, results):
        """ãƒãƒƒãƒãƒ†ã‚¹ãƒˆçµæœåˆ†æ"""
        print(f"\nğŸ“Š ãƒãƒƒãƒãƒ†ã‚¹ãƒˆåˆ†æ:")
        
        valid_results = [r for r in results if 'error' not in r]
        print(f"   æœ‰åŠ¹ãƒ†ã‚¹ãƒˆæ•°: {len(valid_results)}/{len(results)}")
        
        if len(valid_results) == 0:
            return
        
        # ç²¾åº¦è¨ˆç®—
        correct = [r for r in valid_results if r.get('correct_prediction', False)]
        accuracy = len(correct) / len(valid_results) * 100
        print(f"   ç·åˆç²¾åº¦: {accuracy:.1f}% ({len(correct)}/{len(valid_results)})")
        
        # å¹³å‡ä¿¡é ¼åº¦
        confidences = [r['confidence'] for r in valid_results]
        avg_confidence = np.mean(confidences)
        print(f"   å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.3f}")
        
        # å¹³å‡å‡¦ç†æ™‚é–“
        processing_times = [r['processing_time_ms'] for r in valid_results]
        avg_processing_time = np.mean(processing_times)
        print(f"   å¹³å‡å‡¦ç†æ™‚é–“: {avg_processing_time:.1f}ms")
        
        # ã‚¯ãƒ©ã‚¹åˆ¥ç²¾åº¦
        for class_name in ['UnderGrip', 'Success', 'OverGrip']:
            class_results = [r for r in valid_results if r.get('actual_label') == class_name]
            if class_results:
                class_correct = [r for r in class_results if r.get('correct_prediction', False)]
                class_acc = len(class_correct) / len(class_results) * 100
                print(f"   {class_name}ç²¾åº¦: {class_acc:.1f}% ({len(class_correct)}/{len(class_results)})")


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print(f"ğŸ§  ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æŠŠæŒåŠ›åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ")
    print(f"=" * 60)
    print(f"æ”¹å–„ç‰ˆåˆ†é¡æ©Ÿ + ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰åˆ†é¡")
    print(f"UnderGrip(<8N), Success(8-15N), OverGrip(>15N)")
    print(f"=" * 60)
    
    # å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰é¸æŠ
    print(f"\nå®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„:")
    print(f"1. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†é¡ãƒ‡ãƒ¢ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰")
    print(f"2. ãƒãƒƒãƒãƒ†ã‚¹ãƒˆï¼ˆéå»ã®CSVãƒ‡ãƒ¼ã‚¿ã§æ€§èƒ½è©•ä¾¡ï¼‰")
    print(f"3. ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤ºã®ã¿")
    
    choice = input("é¸æŠ (1-3): ").strip()
    
    # åˆ†é¡å™¨åˆæœŸåŒ–
    classifier = RealtimeGripForceClassifier(
        lsl_stream_name='MockEEG',  # å¿…è¦ã«å¿œã˜ã¦å¤‰æ›´
        tcp_host='127.0.0.1',
        tcp_port=12345
    )
    
    if choice == "2":
        # ãƒãƒƒãƒãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰
        print(f"\nğŸ§ª ãƒãƒƒãƒãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰")
        
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        if not classifier.load_model():
            return
        
        # ãƒ†ã‚¹ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªé¸æŠ
        test_dir = input("ãƒ†ã‚¹ãƒˆç”¨ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ï¼ˆç©ºç™½ã§è‡ªå‹•æ¤œç´¢ï¼‰: ").strip()
        
        if not test_dir:
            # è‡ªå‹•æ¤œç´¢
            log_dirs = glob.glob("DDPG_Python/logs/episodes_*")
            if not log_dirs:
                log_dirs = glob.glob("logs/episodes_*")
            
            if log_dirs:
                test_dir = max(log_dirs)  # æœ€æ–°ã®ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
                print(f"ğŸ” è‡ªå‹•é¸æŠ: {test_dir}")
            else:
                print(f"âŒ ãƒ†ã‚¹ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return
        
        # ãƒãƒƒãƒãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        tester = BatchClassificationTester(classifier)
        tester.test_with_saved_episodes(test_dir)
        
    elif choice == "3":
        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤ºã®ã¿
        print(f"\nğŸ“‹ ãƒ¢ãƒ‡ãƒ«æƒ…å ±è¡¨ç¤º")
        classifier.load_model()
        
    else:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼šãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¢
        print(f"\nğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†é¡ãƒ‡ãƒ¢")
        classifier.run_demo()


if __name__ == "__main__":
    main()