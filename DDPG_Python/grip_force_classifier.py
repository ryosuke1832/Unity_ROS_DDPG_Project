#!/usr/bin/env python3
"""
EEGæŠŠæŒåŠ›åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ 
tcp_lsl_sync_systemã‹ã‚‰ä¿å­˜ã•ã‚ŒãŸCSVãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦æŠŠæŒåŠ›ã®åˆ†é¡å™¨ã‚’å­¦ç¿’ã—ã€
ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§EEGãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æŠŠæŒåŠ›ãƒ¬ãƒ™ãƒ«ã‚’åˆ¤å®šã™ã‚‹ã‚·ã‚¹ãƒ†ãƒ 

æŠŠæŒåŠ›åˆ†é¡:
- UnderGrip: æŠŠæŒåŠ› < 8N
- Success: 8N <= æŠŠæŒåŠ› <= 15N  
- OverGrip: æŠŠæŒåŠ› > 15N
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import glob
import os
import sys
import time
import threading
import queue
import json
import pickle
from datetime import datetime
from collections import deque, Counter
from typing import List, Tuple, Dict, Optional, Any
import warnings
warnings.filterwarnings('ignore')

# tcp_lsl_sync_systemã‹ã‚‰å¿…è¦ãªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from eeg_receiver import LSLEEGReceiver
    from unity_tcp_interface import EEGTCPInterface
    from eeg_neuroadaptation_preprocessor import NeuroadaptationEEGPreprocessor
except ImportError:
    print("âš ï¸ tcp_lsl_sync_systemã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    print("   ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’DDPG_Pythonãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã§å®Ÿè¡Œã—ã¦ãã ã•ã„")


class EEGNetClassifier(nn.Module):
    """
    EEGNet: æŠŠæŒåŠ›åˆ†é¡ç”¨ã®CNNãƒ¢ãƒ‡ãƒ«
    3ã¤ã®ã‚¯ãƒ©ã‚¹ï¼ˆUnderGrip, Success, OverGripï¼‰ã‚’åˆ†é¡
    """
    
    def __init__(self, n_channels=32, n_classes=3, input_window_samples=300, 
                 dropout=0.25, kernLength=64, F1=8, D=2, F2=16):
        super(EEGNetClassifier, self).__init__()
        
        self.n_channels = n_channels
        self.n_classes = n_classes
        self.input_window_samples = input_window_samples
        
        # Block 1: Temporal Convolution
        self.firstconv = nn.Conv2d(1, F1, (1, kernLength), padding=(0, kernLength//2), bias=False)
        self.batchnorm1 = nn.BatchNorm2d(F1)
        
        # Block 2: Depthwise Convolution
        self.depthwiseConv = nn.Conv2d(F1, F1*D, (n_channels, 1), groups=F1, bias=False)
        self.batchnorm2 = nn.BatchNorm2d(F1*D)
        self.activation1 = nn.ELU()
        self.pooling1 = nn.AvgPool2d((1, 4))
        self.dropout1 = nn.Dropout(dropout)
        
        # Block 3: Separable Convolution
        self.separableConv = nn.Conv2d(F1*D, F2, (1, 16), padding=(0, 8), bias=False)
        self.batchnorm3 = nn.BatchNorm2d(F2)
        self.activation2 = nn.ELU()
        self.pooling2 = nn.AvgPool2d((1, 8))
        self.dropout2 = nn.Dropout(dropout)
        
        # å‹•çš„ã«åˆ†é¡å™¨ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
        self.flatten = nn.Flatten()
        self._setup_classifier(F2)
        
        print(f"ğŸ§  EEGNetåˆæœŸåŒ–å®Œäº†: {n_channels}ch, {input_window_samples}samples â†’ {n_classes}classes")
    
    def _setup_classifier(self, F2):
        """åˆ†é¡å™¨ã®å‹•çš„ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        # ãƒ€ãƒŸãƒ¼å…¥åŠ›ã§ç‰¹å¾´é‡ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
        with torch.no_grad():
            dummy_input = torch.zeros(1, 1, self.n_channels, self.input_window_samples)
            features = self._forward_features(dummy_input)
            feature_size = features.shape[1]
        
        self.classifier = nn.Linear(feature_size, self.n_classes)
    
    def _forward_features(self, x):
        """ç‰¹å¾´æŠ½å‡ºéƒ¨åˆ†ã®é †ä¼æ’­"""
        # Block 1
        x = self.firstconv(x)
        x = self.batchnorm1(x)
        
        # Block 2
        x = self.depthwiseConv(x)
        x = self.batchnorm2(x)
        x = self.activation1(x)
        x = self.pooling1(x)
        x = self.dropout1(x)
        
        # Block 3
        x = self.separableConv(x)
        x = self.batchnorm3(x)
        x = self.activation2(x)
        x = self.pooling2(x)
        x = self.dropout2(x)
        
        # Flatten
        x = self.flatten(x)
        return x
    
    def forward(self, x):
        """é †ä¼æ’­å‡¦ç†"""
        # x: (batch_size, 1, channels, samples)
        features = self._forward_features(x)
        x = self.classifier(features)
        return x


class GripForceDataset(Dataset):
    """æŠŠæŒåŠ›åˆ†é¡ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ"""
    
    def __init__(self, eeg_data, grip_force_labels, transform=None):
        """
        Args:
            eeg_data: List of (300, 32) EEGã‚¨ãƒãƒƒã‚¯
            grip_force_labels: List of grip force labels (0: UnderGrip, 1: Success, 2: OverGrip)
        """
        self.eeg_data = eeg_data
        self.grip_force_labels = grip_force_labels
        self.transform = transform
        
        # ãƒ©ãƒ™ãƒ«çµ±è¨ˆè¡¨ç¤º
        label_counts = Counter(grip_force_labels)
        label_names = ['UnderGrip', 'Success', 'OverGrip']
        print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆçµ±è¨ˆ:")
        for i, name in enumerate(label_names):
            print(f"   {name}: {label_counts.get(i, 0)}ä»¶")
    
    def __len__(self):
        return len(self.eeg_data)
    
    def __getitem__(self, idx):
        eeg_epoch = self.eeg_data[idx]  # (300, 32)
        label = self.grip_force_labels[idx]
        
        # ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µå‡¦ç†
        if self.transform:
            eeg_epoch = self.transform(eeg_epoch)
        
        # EEGNetã®å…¥åŠ›å½¢å¼ã«å¤‰æ›: (1, 32, 300)
        eeg_tensor = torch.from_numpy(eeg_epoch.T).float()  # (32, 300)
        eeg_tensor = eeg_tensor.unsqueeze(0)  # (1, 32, 300)
        
        return eeg_tensor, torch.tensor(label, dtype=torch.long)


class GripForceClassifierTrainer:
    """æŠŠæŒåŠ›åˆ†é¡å™¨ã®å­¦ç¿’ãƒ»è©•ä¾¡ãƒ»ä¿å­˜ã‚’ç®¡ç†"""
    
    def __init__(self, model, learning_rate=0.001, weight_decay=1e-4):
        self.model = model
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        
        # æœ€é©åŒ–è¨­å®š
        self.optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)
        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            self.optimizer, mode='min', factor=0.5, patience=10
        )
        self.criterion = nn.CrossEntropyLoss()
        
        # å­¦ç¿’å±¥æ­´
        self.train_history = {'loss': [], 'accuracy': []}
        self.val_history = {'loss': [], 'accuracy': []}
        self.best_val_accuracy = 0.0
        
        print(f"ğŸ¯ å­¦ç¿’ç’°å¢ƒ: {self.device}")
    
    def train_epoch(self, train_loader):
        """1ã‚¨ãƒãƒƒã‚¯ã®å­¦ç¿’"""
        self.model.train()
        total_loss = 0.0
        correct = 0
        total = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(self.device), target.to(self.device)
            
            self.optimizer.zero_grad()
            output = self.model(data)
            loss = self.criterion(output, target)
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
            pred = output.argmax(dim=1, keepdim=True)
            correct += pred.eq(target.view_as(pred)).sum().item()
            total += target.size(0)
        
        avg_loss = total_loss / len(train_loader)
        accuracy = 100. * correct / total
        return avg_loss, accuracy
    
    def validate(self, val_loader):
        """æ¤œè¨¼"""
        self.model.eval()
        test_loss = 0
        correct = 0
        total = 0
        all_preds = []
        all_targets = []
        
        with torch.no_grad():
            for data, target in val_loader:
                data, target = data.to(self.device), target.to(self.device)
                output = self.model(data)
                test_loss += self.criterion(output, target).item()
                
                pred = output.argmax(dim=1, keepdim=True)
                correct += pred.eq(target.view_as(pred)).sum().item()
                total += target.size(0)
                
                all_preds.extend(pred.cpu().numpy().flatten())
                all_targets.extend(target.cpu().numpy())
        
        avg_loss = test_loss / len(val_loader)
        accuracy = 100. * correct / total
        return avg_loss, accuracy, all_preds, all_targets

    def train_full(self, train_loader, val_loader, epochs=100, early_stopping=None):
        """å®Œå…¨å­¦ç¿’ãƒ«ãƒ¼ãƒ—

        Args:
            train_loader: å­¦ç¿’ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€
            val_loader: æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€
            epochs: å­¦ç¿’ã‚¨ãƒãƒƒã‚¯æ•°
            early_stopping: é€£ç¶šã‚¨ãƒãƒƒã‚¯æ”¹å–„ãªã—ã§åœæ­¢ã™ã‚‹å›æ•°ã€‚
                None ã®å ´åˆã¯æ—©æœŸçµ‚äº†ã‚’è¡Œã‚ãªã„
        """
        es_text = "ãªã—" if early_stopping is None else early_stopping
        print(f"ğŸ“ å­¦ç¿’é–‹å§‹: {epochs}ã‚¨ãƒãƒƒã‚¯, Early Stopping={es_text}")

        best_epoch = 0
        epochs_without_improvement = 0

        
        for epoch in range(epochs):
            print(f"\n--- Epoch {epoch+1}/{epochs} ---")
            
            # å­¦ç¿’
            train_loss, train_acc = self.train_epoch(train_loader)
            
            # æ¤œè¨¼
            val_loss, val_acc, val_preds, val_targets = self.validate(val_loader)
            
            # å­¦ç¿’ç‡èª¿æ•´
            old_lr = self.optimizer.param_groups[0]['lr']
            self.scheduler.step(val_loss)
            current_lr = self.optimizer.param_groups[0]['lr']
            
            # å­¦ç¿’ç‡å¤‰æ›´ã®è¡¨ç¤º
            if current_lr != old_lr:
                print(f"ğŸ“‰ å­¦ç¿’ç‡èª¿æ•´: {old_lr:.6f} â†’ {current_lr:.6f}")
            
            # å±¥æ­´ä¿å­˜
            self.train_history['loss'].append(train_loss)
            self.train_history['accuracy'].append(train_acc)
            self.val_history['loss'].append(val_loss)
            self.val_history['accuracy'].append(val_acc)
            
            print(f"å­¦ç¿’   : Loss={train_loss:.4f}, Acc={train_acc:.1f}%")
            print(f"æ¤œè¨¼   : Loss={val_loss:.4f}, Acc={val_acc:.1f}%, LR={current_lr:.6f}")
            
            # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«æ›´æ–°
            if val_acc > self.best_val_accuracy:
                self.best_val_accuracy = val_acc
                best_epoch = epoch + 1
                epochs_without_improvement = 0

                # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
                os.makedirs('models', exist_ok=True)
                torch.save(self.model.state_dict(), 'models/best_grip_force_classifier.pth')
                print(f"ğŸ¯ ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«æ›´æ–°! ç²¾åº¦: {val_acc:.1f}%")
            else:
                epochs_without_improvement += 1

            # Early Stopping
            if early_stopping is not None and epochs_without_improvement >= early_stopping:
                print(f"â° Early Stopping: {early_stopping}ã‚¨ãƒãƒƒã‚¯æ”¹å–„ãªã—")
                break
        
        print(f"\nâœ… å­¦ç¿’å®Œäº†!")
        print(f"   ãƒ™ã‚¹ãƒˆæ¤œè¨¼ç²¾åº¦: {self.best_val_accuracy:.1f}% (Epoch {best_epoch})")
        return self.best_val_accuracy
    
    def evaluate_final(self, test_loader):
        """æœ€çµ‚è©•ä¾¡"""
        # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
        if os.path.exists('models/best_grip_force_classifier.pth'):
            self.model.load_state_dict(torch.load('models/best_grip_force_classifier.pth'))
        
        test_loss, test_acc, test_preds, test_targets = self.validate(test_loader)
        
        print(f"\nğŸ“Š æœ€çµ‚ãƒ†ã‚¹ãƒˆçµæœ:")
        print(f"   ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_acc:.1f}%")
        print(f"   ãƒ†ã‚¹ãƒˆæå¤±: {test_loss:.4f}")
        
        # åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ
        class_names = ['UnderGrip', 'Success', 'OverGrip']
        print(f"\nğŸ“‹ åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆ:")
        print(classification_report(test_targets, test_preds, target_names=class_names))
        
        # æ··åŒè¡Œåˆ—ã‚’ä¿å­˜ï¼ˆè¡¨ç¤ºã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        try:
            cm = confusion_matrix(test_targets, test_preds)
            plt.figure(figsize=(8, 6))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                       xticklabels=class_names, yticklabels=class_names)
            plt.title('æŠŠæŒåŠ›åˆ†é¡ - æ··åŒè¡Œåˆ—')
            plt.xlabel('äºˆæ¸¬')
            plt.ylabel('å®Ÿéš›')
            plt.tight_layout()
            
            cm_path = f'models/confusion_matrix_{datetime.now().strftime("%Y%m%d_%H%M%S")}.png'
            plt.savefig(cm_path)
            print(f"æ··åŒè¡Œåˆ—ä¿å­˜: {cm_path}")
            plt.close()  # GUIç’°å¢ƒã§ãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ãŸã‚
        except Exception as e:
            print(f"æ··åŒè¡Œåˆ—ä¿å­˜ã‚¨ãƒ©ãƒ¼ï¼ˆç„¡è¦–å¯èƒ½ï¼‰: {e}")
        
        return test_acc


def load_csv_data(csv_dir: str) -> Tuple[List[np.ndarray], List[int]]:
    """
    tcp_lsl_sync_systemã§ä¿å­˜ã•ã‚ŒãŸCSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    
    Args:
        csv_dir: CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        
    Returns:
        eeg_data_list: EEGãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ [(300, 32), ...]
        grip_force_labels: æŠŠæŒåŠ›ãƒ©ãƒ™ãƒ«ã®ãƒªã‚¹ãƒˆ [0, 1, 2, ...]
    """
    print(f"ğŸ“‚ CSVãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–‹å§‹: {csv_dir}")
    
    eeg_data_list = []
    grip_force_labels = []
    
    # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    info_files = glob.glob(os.path.join(csv_dir, "*_info.csv"))
    
    if not info_files:
        print(f"âŒ ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_dir}")
        return eeg_data_list, grip_force_labels
    
    print(f"ğŸ“‹ ç™ºè¦‹ã—ãŸã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰: {len(info_files)}ä»¶")
    
    for info_file in sorted(info_files):
        try:
            # ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰æƒ…å ±ã‚’èª­ã¿è¾¼ã¿
            info_df = pd.read_csv(info_file)
            episode_id = info_df['episode_id'].iloc[0]
            grip_force = info_df['grip_force'].iloc[0]
            
            # æŠŠæŒåŠ›ã‹ã‚‰ãƒ©ãƒ™ãƒ«ã‚’æ±ºå®š
            if grip_force < 8.0:
                label = 0  # UnderGrip
                label_name = "UnderGrip"
            elif grip_force > 15.0:
                label = 2  # OverGrip  
                label_name = "OverGrip"
            else:
                label = 1  # Success
                label_name = "Success"
            
            # å¯¾å¿œã™ã‚‹EEGãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            eeg_file = info_file.replace('_info.csv', '_eeg.csv')
            if os.path.exists(eeg_file):
                eeg_df = pd.read_csv(eeg_file)
                
                # EEGãƒ‡ãƒ¼ã‚¿éƒ¨åˆ†ã‚’æŠ½å‡ºï¼ˆãƒãƒ£ãƒ³ãƒãƒ«åˆ—ã®ã¿ï¼‰
                channel_cols = [col for col in eeg_df.columns if col.startswith('ch_')]
                eeg_data = eeg_df[channel_cols].values  # (samples, channels)
                
                # 300ã‚µãƒ³ãƒ—ãƒ«ï¼ˆ1.2ç§’ï¼‰ã«èª¿æ•´
                if eeg_data.shape[0] >= 300:
                    eeg_data = eeg_data[:300, :]  # æœ€åˆã®300ã‚µãƒ³ãƒ—ãƒ«
                    
                    # 32ãƒãƒ£ãƒ³ãƒãƒ«ã«èª¿æ•´
                    if eeg_data.shape[1] >= 32:
                        eeg_data = eeg_data[:, :32]
                    else:
                        # ãƒãƒ£ãƒ³ãƒãƒ«æ•°ãŒè¶³ã‚Šãªã„å ´åˆã¯ã‚¼ãƒ­ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
                        padding = np.zeros((300, 32 - eeg_data.shape[1]))
                        eeg_data = np.hstack([eeg_data, padding])
                    
                    eeg_data_list.append(eeg_data)
                    grip_force_labels.append(label)
                    
                    print(f"   Episode {episode_id:04d}: æŠŠæŒåŠ›={grip_force:.1f}N â†’ {label_name}")
                
            else:
                print(f"âš ï¸ EEGãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {eeg_file}")
                
        except Exception as e:
            print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {info_file}, {e}")
            continue
    
    print(f"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(eeg_data_list)}ä»¶")
    
    # ãƒ©ãƒ™ãƒ«åˆ†å¸ƒç¢ºèª
    label_counts = Counter(grip_force_labels)
    label_names = ['UnderGrip', 'Success', 'OverGrip']
    print(f"ğŸ“Š ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ:")
    for i, name in enumerate(label_names):
        print(f"   {name}: {label_counts.get(i, 0)}ä»¶")
    
    return eeg_data_list, grip_force_labels


def train_grip_force_classifier(csv_dir: str, model_save_path: str = 'models/grip_force_classifier.pth'):
    """
    ä¿å­˜ã•ã‚ŒãŸCSVãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æŠŠæŒåŠ›åˆ†é¡å™¨ã‚’å­¦ç¿’
    
    Args:
        csv_dir: CSVãƒ‡ãƒ¼ã‚¿ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        model_save_path: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ãƒ‘ã‚¹
        
    Returns:
        dict: å­¦ç¿’çµæœã®è©³ç´°æƒ…å ±
    """
    print(f"ğŸ“ æŠŠæŒåŠ›åˆ†é¡å™¨å­¦ç¿’é–‹å§‹")
    print(f"=" * 60)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    eeg_data_list, grip_force_labels = load_csv_data(csv_dir)
    
    if len(eeg_data_list) == 0:
        print(f"âŒ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return None
    
    # æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°ãƒã‚§ãƒƒã‚¯
    label_counts = Counter(grip_force_labels)
    min_samples = min(label_counts.values()) if label_counts else 0
    
    if min_samples < 1:  # æœ€ä½3ä»¶ï¼ˆtrain, val, testã«1ä»¶ãšã¤ï¼‰
        print(f"âš ï¸ å„ã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã™ãã¾ã™ (æœ€å°: {min_samples}ä»¶)")
        print(f"   å„ã‚¯ãƒ©ã‚¹æœ€ä½5ä»¶ä»¥ä¸Šæ¨å¥¨")
        return None
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
    dataset = GripForceDataset(eeg_data_list, grip_force_labels)
    
    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰² (70% train, 15% val, 15% test)
    total_size = len(dataset)
    train_size = max(1, int(0.7 * total_size))
    val_size = max(1, int(0.15 * total_size))
    test_size = total_size - train_size - val_size
    
    # test_sizeãŒ0ã«ãªã‚‹å ´åˆã®èª¿æ•´
    if test_size <= 0:
        test_size = 1
        val_size = max(1, total_size - train_size - test_size)
        train_size = total_size - val_size - test_size
    
    train_dataset, val_dataset, test_dataset = random_split(
        dataset, [train_size, val_size, test_size]
    )
    
    print(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿åˆ†å‰²: Train={train_size}, Val={val_size}, Test={test_size}")
    
    # DataLoaderä½œæˆï¼ˆbatch_sizeã‚’å‹•çš„èª¿æ•´ï¼‰
    batch_size = min(8, train_size)
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    
    # ãƒ¢ãƒ‡ãƒ«ä½œæˆ
    model = EEGNetClassifier(n_channels=32, n_classes=3, input_window_samples=300)
    trainer = GripForceClassifierTrainer(model)
    
    # å­¦ç¿’å®Ÿè¡Œï¼ˆã‚¨ãƒãƒƒã‚¯æ•°ã‚’å‹•çš„èª¿æ•´ï¼‰
    epochs = min(100, max(20, total_size * 2))

    print(f"ğŸš€ å­¦ç¿’é–‹å§‹... (epochs={epochs}, early_stopping=None)")
    best_val_accuracy = trainer.train_full(
        train_loader, val_loader,
        epochs=epochs,
    )
    
    # æœ€çµ‚è©•ä¾¡
    print(f"\nğŸ” æœ€çµ‚ãƒ†ã‚¹ãƒˆè©•ä¾¡...")
    test_accuracy = trainer.evaluate_final(test_loader)
    
    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    os.makedirs(os.path.dirname(model_save_path), exist_ok=True)
    torch.save(model.state_dict(), model_save_path)
    
    # çµæœã‚µãƒãƒªãƒ¼
    result = {
        'model_path': model_save_path,
        'test_accuracy': test_accuracy,
        'val_accuracy': best_val_accuracy,
        'total_samples': total_size,
        'train_samples': train_size,
        'test_samples': test_size,
        'class_distribution': dict(label_counts),
        'timestamp': datetime.now().isoformat()
    }
    
    # çµæœä¿å­˜
    result_file = model_save_path.replace('.pth', '_result.json')
    with open(result_file, 'w') as f:
        json.dump(result, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ‰ å­¦ç¿’å®Œäº†!")
    print(f"   ãƒ¢ãƒ‡ãƒ«ä¿å­˜: {model_save_path}")
    print(f"   çµæœä¿å­˜: {result_file}")
    print(f"   ãƒ†ã‚¹ãƒˆç²¾åº¦: {test_accuracy:.1f}%")
    
    return result


class RealtimeGripForceClassifier:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æŠŠæŒåŠ›åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self, model_path: str, lsl_stream_name: str = 'X.on-102807-0109', 
                 tcp_host: str = '127.0.0.1', tcp_port: int = 12345):
        """
        Args:
            model_path: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ã‚¹
            lsl_stream_name: LSLã‚¹ãƒˆãƒªãƒ¼ãƒ å
            tcp_host: TCPãƒ›ã‚¹ãƒˆ
            tcp_port: TCPãƒãƒ¼ãƒˆ
        """
        self.model_path = model_path
        self.lsl_stream_name = lsl_stream_name
        self.tcp_host = tcp_host
        self.tcp_port = tcp_port
        
        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = EEGNetClassifier(n_channels=32, n_classes=3, input_window_samples=300)
        self.model.load_state_dict(torch.load(model_path, map_location=self.device))
        self.model.to(self.device)
        self.model.eval()
        
        self.class_names = ['UnderGrip', 'Success', 'OverGrip']
        
        # LSLå—ä¿¡ã‚·ã‚¹ãƒ†ãƒ ï¼ˆImportErrorã«å¯¾å¿œï¼‰
        try:
            self.eeg_receiver = LSLEEGReceiver(stream_name=lsl_stream_name)
            self.eeg_preprocessor = NeuroadaptationEEGPreprocessor(
                sampling_rate=250,
                enable_asr=True,
                enable_ica=False
            )
            self.tcp_interface = EEGTCPInterface(host=tcp_host, port=tcp_port)
            self.system_available = True
        except Exception as e:
            print(f"âš ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.system_available = False
        
        # ãƒ‡ãƒ¼ã‚¿ãƒãƒƒãƒ•ã‚¡
        self.lsl_data_buffer = deque(maxlen=2500)  # 10ç§’åˆ†
        self.lsl_timestamp_buffer = deque(maxlen=2500)
        
        # å®Ÿè¡Œåˆ¶å¾¡
        self.is_running = False
        self.buffer_lock = threading.Lock()
        self.classification_count = 0
        
        print(f"ğŸ§  ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æŠŠæŒåŠ›åˆ†é¡å™¨åˆæœŸåŒ–å®Œäº†")
        print(f"   ãƒ¢ãƒ‡ãƒ«: {model_path}")
        print(f"   ãƒ‡ãƒã‚¤ã‚¹: {self.device}")
        print(f"   ã‚¯ãƒ©ã‚¹: {self.class_names}")
        print(f"   ã‚·ã‚¹ãƒ†ãƒ åˆ©ç”¨å¯èƒ½: {self.system_available}")
    
    def classify_eeg_epoch(self, eeg_data: np.ndarray) -> Tuple[str, int, float]:
        """
        EEGã‚¨ãƒãƒƒã‚¯ã‚’åˆ†é¡
        
        Args:
            eeg_data: (300, 32) ã®EEGãƒ‡ãƒ¼ã‚¿
            
        Returns:
            (äºˆæ¸¬ã‚¯ãƒ©ã‚¹å, äºˆæ¸¬ã‚¯ãƒ©ã‚¹ID, ä¿¡é ¼åº¦)
        """
        try:
            # ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†
            if eeg_data.shape[0] != 300 or eeg_data.shape[1] != 32:
                # ã‚µã‚¤ã‚ºèª¿æ•´
                if eeg_data.shape[0] >= 300:
                    eeg_data = eeg_data[:300, :]
                else:
                    # ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°
                    padding = np.zeros((300 - eeg_data.shape[0], eeg_data.shape[1]))
                    eeg_data = np.vstack([eeg_data, padding])
                
                if eeg_data.shape[1] >= 32:
                    eeg_data = eeg_data[:, :32]
                else:
                    padding = np.zeros((300, 32 - eeg_data.shape[1]))
                    eeg_data = np.hstack([eeg_data, padding])
            
            # ãƒ†ãƒ³ã‚½ãƒ«å¤‰æ›: (1, 1, 32, 300)
            eeg_tensor = torch.from_numpy(eeg_data.T).float()  # (32, 300)
            eeg_tensor = eeg_tensor.unsqueeze(0).unsqueeze(0)  # (1, 1, 32, 300)
            eeg_tensor = eeg_tensor.to(self.device)
            
            # æ¨è«–å®Ÿè¡Œ
            with torch.no_grad():
                outputs = self.model(eeg_tensor)
                probabilities = F.softmax(outputs, dim=1)
                
                predicted_class_id = torch.argmax(probabilities, dim=1).item()
                confidence = probabilities[0, predicted_class_id].item()
                predicted_class_name = self.class_names[predicted_class_id]
            
            return predicted_class_name, predicted_class_id, confidence
            
        except Exception as e:
            print(f"âš ï¸ åˆ†é¡ã‚¨ãƒ©ãƒ¼: {e}")
            return "ERROR", -1, 0.0
    
    def test_with_dummy_data(self):
        """ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ã®åˆ†é¡ãƒ†ã‚¹ãƒˆ"""
        print(f"ğŸ§ª ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ†ã‚¹ãƒˆé–‹å§‹")
        
        # ãƒ€ãƒŸãƒ¼EEGãƒ‡ãƒ¼ã‚¿ä½œæˆ
        dummy_eeg = np.random.randn(300, 32)
        
        # åˆ†é¡å®Ÿè¡Œ
        prediction, class_id, confidence = self.classify_eeg_epoch(dummy_eeg)
        
        print(f"âœ… ãƒ†ã‚¹ãƒˆçµæœ:")
        print(f"   äºˆæ¸¬: {prediction}")
        print(f"   ã‚¯ãƒ©ã‚¹ID: {class_id}")
        print(f"   ä¿¡é ¼åº¦: {confidence:.3f}")
        
        return prediction != "ERROR"


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print(f"ğŸ§  EEGæŠŠæŒåŠ›åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ")
    print(f"=" * 60)
    print(f"é¸æŠã—ã¦ãã ã•ã„:")
    print(f"1. CSVãƒ‡ãƒ¼ã‚¿ã‹ã‚‰åˆ†é¡å™¨ã‚’å­¦ç¿’")
    print(f"2. å­¦ç¿’æ¸ˆã¿åˆ†é¡å™¨ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ¤å®š")
    print(f"3. ä¸¡æ–¹å®Ÿè¡Œï¼ˆå­¦ç¿’â†’åˆ¤å®šï¼‰")
    print(f"4. åˆ†é¡å™¨ãƒ†ã‚¹ãƒˆï¼ˆãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼‰")
    
    choice = input(f"é¸æŠ (1-4): ").strip()
    
    if choice == "1":
        # å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰
        print(f"\nğŸ“š å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰é¸æŠ")
        csv_dir = input(f"CSVãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹: ").strip()
        
        if not csv_dir:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ã‚¹æ¤œç´¢
            log_dirs = glob.glob("DDPG_Python/logs/episodes_*")
            if log_dirs:
                csv_dir = max(log_dirs)  # æœ€æ–°ã®ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
                print(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä½¿ç”¨: {csv_dir}")
            else:
                print(f"âŒ CSVãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return
        
        if not os.path.exists(csv_dir):
            print(f"âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {csv_dir}")
            return
        
        # å­¦ç¿’å®Ÿè¡Œ
        result = train_grip_force_classifier(csv_dir)
        
        if result:
            print(f"\nâœ… å­¦ç¿’å®Œäº†!")
            print(f"   ãƒ¢ãƒ‡ãƒ«: {result['model_path']}")
            print(f"   ãƒ†ã‚¹ãƒˆç²¾åº¦: {result['test_accuracy']:.1f}%")
        else:
            print(f"âŒ å­¦ç¿’å¤±æ•—")
    
    elif choice == "2":
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ¤å®šãƒ¢ãƒ¼ãƒ‰
        print(f"\nğŸ¯ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ¤å®šãƒ¢ãƒ¼ãƒ‰é¸æŠ")
        model_path = input(f"å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: ").strip()
        
        if not model_path:
            model_path = "models/best_grip_force_classifier.pth"
            print(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä½¿ç”¨: {model_path}")
        
        if not os.path.exists(model_path):
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {model_path}")
            return
        
        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†é¡å™¨ä½œæˆ
        classifier = RealtimeGripForceClassifier(
            model_path=model_path,
            lsl_stream_name='MockEEG',
            tcp_host='127.0.0.1',
            tcp_port=12345
        )
        
        if not classifier.system_available:
            print(f"âŒ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
            print(f"   tcp_lsl_sync_systemã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
            return
        
        # åˆ†é¡é–‹å§‹
        if classifier.start_classification():
            try:
                print(f"\nğŸ’¡ ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒä¸­...")
                print(f"   TCPã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã™ã‚‹ã¨åˆ†é¡å®Ÿè¡Œ")
                print(f"   Ctrl+C ã§çµ‚äº†")
                
                while True:
                    time.sleep(1.0)
                    
            except KeyboardInterrupt:
                print(f"\nâ¹ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼åœæ­¢")
            finally:
                classifier.stop_classification()
        
    elif choice == "3":
        # ä¸¡æ–¹å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰
        print(f"\nğŸ”„ å­¦ç¿’â†’åˆ¤å®šãƒ¢ãƒ¼ãƒ‰é¸æŠ")
        csv_dir = input(f"CSVãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹: ").strip()
        
        if not csv_dir:
            log_dirs = glob.glob("DDPG_Python/logs/episodes_*")
            if log_dirs:
                csv_dir = max(log_dirs)
                print(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä½¿ç”¨: {csv_dir}")
            else:
                print(f"âŒ CSVãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return
        
        if not os.path.exists(csv_dir):
            print(f"âŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {csv_dir}")
            return
        
        # Step 1: å­¦ç¿’
        print(f"\nğŸ“ Step 1: åˆ†é¡å™¨å­¦ç¿’")
        result = train_grip_force_classifier(csv_dir)
        
        if not result:
            print(f"âŒ å­¦ç¿’å¤±æ•—")
            return
        
        print(f"âœ… å­¦ç¿’å®Œäº†! ãƒ†ã‚¹ãƒˆç²¾åº¦: {result['test_accuracy']:.1f}%")
        
        # Step 2: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ¤å®š
        if result['test_accuracy'] > 30:  # 30%ä»¥ä¸Šã§å®Ÿç”¨å¯èƒ½ï¼ˆå°‘ãƒ‡ãƒ¼ã‚¿å¯¾å¿œï¼‰
            print(f"\nğŸ¯ Step 2: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ¤å®šé–‹å§‹")
            
            classifier = RealtimeGripForceClassifier(
                model_path=result['model_path'],
                lsl_stream_name='MockEEG',
                tcp_host='127.0.0.1',
                tcp_port=12345
            )
            
            if classifier.system_available and classifier.start_classification():
                try:
                    print(f"\nğŸ’¡ ä¸¡æ–¹ã®ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒä¸­...")
                    print(f"   å­¦ç¿’å®Œäº† â†’ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ åˆ†é¡ä¸­")
                    print(f"   TCPã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ä¿¡ã™ã‚‹ã¨åˆ†é¡å®Ÿè¡Œ")
                    print(f"   Ctrl+C ã§çµ‚äº†")
                    
                    while True:
                        time.sleep(1.0)
                        
                except KeyboardInterrupt:
                    print(f"\nâ¹ï¸ ãƒ¦ãƒ¼ã‚¶ãƒ¼åœæ­¢")
                finally:
                    classifier.stop_classification()
            else:
                print(f"âš ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
                print(f"   ãƒ¢ãƒ‡ãƒ«ã¯å­¦ç¿’æ¸ˆã¿ã§ã™: {result['model_path']}")
        else:
            print(f"âš ï¸ åˆ†é¡ç²¾åº¦ãŒä½ã™ãã¾ã™ ({result['test_accuracy']:.1f}%)")
            print(f"   ã‚ˆã‚Šå¤šãã®ãƒ‡ãƒ¼ã‚¿åé›†ãŒå¿…è¦ã§ã™")
    
    elif choice == "4":
        # ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰
        print(f"\nğŸ§ª åˆ†é¡å™¨ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰")
        model_path = input(f"å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ‘ã‚¹: ").strip()
        
        if not model_path:
            model_path = "models/best_grip_force_classifier.pth"
            print(f"ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä½¿ç”¨: {model_path}")
        
        if not os.path.exists(model_path):
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {model_path}")
            return
        
        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        classifier = RealtimeGripForceClassifier(
            model_path=model_path,
            lsl_stream_name='MockEEG',
            tcp_host='127.0.0.1',
            tcp_port=12345
        )
        
        success = classifier.test_with_dummy_data()
        
        if success:
            print(f"âœ… åˆ†é¡å™¨ãƒ†ã‚¹ãƒˆæˆåŠŸ!")
        else:
            print(f"âŒ åˆ†é¡å™¨ãƒ†ã‚¹ãƒˆå¤±æ•—")
    
    else:
        print(f"âŒ ç„¡åŠ¹ãªé¸æŠã§ã™")


# å˜ä½“ãƒ†ã‚¹ãƒˆç”¨é–¢æ•°
def test_csv_loading():
    """CSVèª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ"""
    print(f"ğŸ§ª CSVèª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆ")
    
    # æœ€æ–°ã®ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¤œç´¢
    log_dirs = glob.glob("DDPG_Python/logs/episodes_*")
    if not log_dirs:
        print(f"âŒ ãƒ†ã‚¹ãƒˆç”¨CSVãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    
    csv_dir = max(log_dirs)
    print(f"ãƒ†ã‚¹ãƒˆå¯¾è±¡: {csv_dir}")
    
    eeg_data_list, grip_force_labels = load_csv_data(csv_dir)
    
    if eeg_data_list:
        print(f"âœ… ãƒ†ã‚¹ãƒˆæˆåŠŸ!")
        print(f"   ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(eeg_data_list)}")
        print(f"   EEGå½¢çŠ¶: {eeg_data_list[0].shape}")
        print(f"   ãƒ©ãƒ™ãƒ«ä¾‹: {grip_force_labels[:5]}")
        return True
    else:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—")
        return False


def test_model_inference():
    """ãƒ¢ãƒ‡ãƒ«æ¨è«–ãƒ†ã‚¹ãƒˆ"""
    print(f"ğŸ§ª ãƒ¢ãƒ‡ãƒ«æ¨è«–ãƒ†ã‚¹ãƒˆ")
    
    try:
        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ä½œæˆ
        model = EEGNetClassifier(n_channels=32, n_classes=3, input_window_samples=300)
        model.eval()
        
        # ãƒ€ãƒŸãƒ¼EEGãƒ‡ãƒ¼ã‚¿
        dummy_eeg = np.random.randn(300, 32)
        
        # ãƒ†ãƒ³ã‚½ãƒ«å¤‰æ›
        eeg_tensor = torch.from_numpy(dummy_eeg.T).float()  # (32, 300)
        eeg_tensor = eeg_tensor.unsqueeze(0).unsqueeze(0)  # (1, 1, 32, 300)
        
        # æ¨è«–å®Ÿè¡Œ
        with torch.no_grad():
            outputs = model(eeg_tensor)
            probabilities = F.softmax(outputs, dim=1)
            
            predicted_class_id = torch.argmax(probabilities, dim=1).item()
            confidence = probabilities[0, predicted_class_id].item()
        
        class_names = ['UnderGrip', 'Success', 'OverGrip']
        predicted_class_name = class_names[predicted_class_id]
        
        print(f"âœ… æ¨è«–ãƒ†ã‚¹ãƒˆæˆåŠŸ!")
        print(f"   å…¥åŠ›å½¢çŠ¶: {eeg_tensor.shape}")
        print(f"   å‡ºåŠ›å½¢çŠ¶: {outputs.shape}")
        print(f"   äºˆæ¸¬ã‚¯ãƒ©ã‚¹: {predicted_class_name}")
        print(f"   ä¿¡é ¼åº¦: {confidence:.3f}")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨è«–ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        return False


if __name__ == "__main__":
    import os
    import sys
    import glob
    import time
    import numpy as np
    import torch
    import torch.nn.functional as F
    from datetime import datetime
    
    # å¿…è¦ãªé–¢æ•°ã‚„ã‚¯ãƒ©ã‚¹ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆå®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ï¼‰
    # from grip_force_classifier import train_grip_force_classifier, RealtimeGripForceClassifier, EEGNetClassifier, load_csv_data
    
    print(f"ğŸ§  EEGæŠŠæŒåŠ›åˆ†é¡ã‚·ã‚¹ãƒ†ãƒ ")
    print(f"tcp_lsl_sync_systemã®CSVãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦EEGNetã§æŠŠæŒåŠ›ã‚’åˆ†é¡")
    print(f"UnderGrip(<8N), Success(8-15N), OverGrip(>15N)")
    print(f"")
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ã®å®Ÿè¡Œ
    if len(sys.argv) > 1:
        if sys.argv[1] == "test_csv":
            test_csv_loading()
        elif sys.argv[1] == "test_model":
            test_model_inference()
        elif sys.argv[1] == "test_all":
            print("ğŸ§ª å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")
            csv_ok = test_csv_loading()
            print("")
            model_ok = test_model_inference()
            print(f"\nçµæœ: CSV={csv_ok}, Model={model_ok}")
        else:
            main()
    else:
        main()